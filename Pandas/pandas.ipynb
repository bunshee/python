{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Pandas is a powerful Python library for data manipulation and analysis. It provides data structures like Series (1-dimensional) and DataFrame (2-dimensional) that allow you to work with structured data efficiently.\n",
    "# Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    7\n",
      "4    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a simple Series\n",
    "s = pd.Series([1, 3, 5, 7, 9])\n",
    "\n",
    "# Display the Series\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Creation\n",
    "A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. It's the most commonly used Pandas object and can be created from various data sources like dictionaries, lists, or NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age           City\n",
      "0    Alice   25       New York\n",
      "1      Bob   30  San Francisco\n",
      "2  Charlie   35         London\n",
      "3    David   28         Sydney\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    4 non-null      object\n",
      " 1   Age     4 non-null      int64 \n",
      " 2   City    4 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 224.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with some data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 28],\n",
    "    'City': ['New York', 'San Francisco', 'London', 'Sydney']\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection and Indexing\n",
    "Pandas provides various methods to select, filter, and access data in a DataFrame. You can select columns, rows, or specific cells based on labels or integer locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'A':\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "Name: A, dtype: int64\n",
      "\n",
      "Columns 'A' and 'C':\n",
      "   A    C\n",
      "0  1  100\n",
      "1  2  200\n",
      "2  3  300\n",
      "3  4  400\n",
      "4  5  500\n",
      "\n",
      "Rows 1 to 3:\n",
      "   A   B    C\n",
      "1  2  20  200\n",
      "2  3  30  300\n",
      "3  4  40  400\n",
      "\n",
      "Rows 1 to 3 (by integer location):\n",
      "   A   B    C\n",
      "1  2  20  200\n",
      "2  3  30  300\n",
      "3  4  40  400\n",
      "\n",
      "Value at row 2, column 'B':\n",
      "30\n",
      "\n",
      "Rows where 'A' > 3:\n",
      "   A   B    C\n",
      "3  4  40  400\n",
      "4  5  50  500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50],\n",
    "    'C': [100, 200, 300, 400, 500]\n",
    "})\n",
    "\n",
    "# Select a single column\n",
    "print(\"Column 'A':\")\n",
    "print(df['A'])\n",
    "\n",
    "# Select multiple columns\n",
    "print(\"\\nColumns 'A' and 'C':\")\n",
    "print(df[['A', 'C']])\n",
    "\n",
    "# Select rows by index label\n",
    "print(\"\\nRows 1 to 3:\")\n",
    "print(df.loc[1:3])\n",
    "\n",
    "# Select rows by integer location\n",
    "print(\"\\nRows 1 to 3 (by integer location):\")\n",
    "print(df.iloc[1:4])\n",
    "\n",
    "# Select specific cells\n",
    "print(\"\\nValue at row 2, column 'B':\")\n",
    "print(df.loc[2, 'B'])\n",
    "\n",
    "# Boolean indexing\n",
    "print(\"\\nRows where 'A' > 3:\")\n",
    "print(df[df['A'] > 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "Data cleaning is a crucial step in data analysis. Pandas provides various methods to handle missing values, remove duplicates, and transform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B  C\n",
      "0  1.0  5.0  a\n",
      "1  2.0  6.0  b\n",
      "2  NaN  7.0  c\n",
      "3  4.0  NaN  d\n",
      "4  5.0  9.0  e\n",
      "5  5.0  9.0  e\n",
      "\n",
      "DataFrame with filled missing values:\n",
      "     A    B  C\n",
      "0  1.0  5.0  a\n",
      "1  2.0  6.0  b\n",
      "2  3.4  7.0  c\n",
      "3  4.0  7.2  d\n",
      "4  5.0  9.0  e\n",
      "5  5.0  9.0  e\n",
      "\n",
      "DataFrame with duplicates removed:\n",
      "     A    B  C\n",
      "0  1.0  5.0  a\n",
      "1  2.0  6.0  b\n",
      "2  NaN  7.0  c\n",
      "3  4.0  NaN  d\n",
      "4  5.0  9.0  e\n",
      "\n",
      "Transformed DataFrame:\n",
      "   A    B  C\n",
      "0  1  5.0  A\n",
      "1  2  6.0  B\n",
      "2  0  7.0  C\n",
      "3  4  NaN  D\n",
      "4  5  9.0  E\n",
      "5  5  9.0  E\n",
      "\n",
      "DataFrame with reset index:\n",
      "     A    B  C\n",
      "0  1.0  5.0  a\n",
      "1  2.0  6.0  b\n",
      "2  NaN  7.0  c\n",
      "3  4.0  NaN  d\n",
      "4  5.0  9.0  e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badrg\\AppData\\Local\\Temp\\ipykernel_17308\\1870542798.py:15: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_filled = df.fillna(df.mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with some missing values and duplicates\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5, 5],\n",
    "    'B': [5, 6, 7, np.nan, 9, 9],\n",
    "    'C': ['a', 'b', 'c', 'd', 'e', 'e']\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Handle missing values\n",
    "df_filled = df.fillna(df.mean())\n",
    "print(\"\\nDataFrame with filled missing values:\")\n",
    "print(df_filled)\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_dupes = df.drop_duplicates()\n",
    "print(\"\\nDataFrame with duplicates removed:\")\n",
    "print(df_no_dupes)\n",
    "\n",
    "# Transform data: convert column A to integers and capitalize column C\n",
    "df['A'] = df['A'].fillna(0).astype(int)\n",
    "df['C'] = df['C'].str.upper()\n",
    "\n",
    "print(\"\\nTransformed DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Reset index after removing duplicates\n",
    "df_reset = df_no_dupes.reset_index(drop=True)\n",
    "print(\"\\nDataFrame with reset index:\")\n",
    "print(df_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation and Grouping\n",
    "Data aggregation and grouping are powerful features in Pandas that allow you to compute summary statistics and perform operations on groups of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Category  Value  Quantity\n",
      "0        A     10         1\n",
      "1        B     20         2\n",
      "2        A     30         3\n",
      "3        B     40         4\n",
      "4        A     50         5\n",
      "5        C     60         6\n",
      "6        C     70         7\n",
      "7        B     80         8\n",
      "\n",
      "Grouped and aggregated data:\n",
      "              Value              Quantity          \n",
      "               mean  sum min max      sum      mean\n",
      "Category                                           \n",
      "A         30.000000   90  10  50        9  3.000000\n",
      "B         46.666667  140  20  80       14  4.666667\n",
      "C         65.000000  130  60  70       13  6.500000\n",
      "\n",
      "Custom aggregation (range of Values for each Category):\n",
      "          Value\n",
      "Category       \n",
      "A            40\n",
      "B            60\n",
      "C            10\n",
      "\n",
      "Grouped data with reset column names:\n",
      "  Category  Value_Mean  Value_Sum  Value_Min  Value_Max  Quantity_Sum  \\\n",
      "0        A   30.000000         90         10         50             9   \n",
      "1        B   46.666667        140         20         80            14   \n",
      "2        C   65.000000        130         60         70            13   \n",
      "\n",
      "   Quantity_Mean  \n",
      "0       3.000000  \n",
      "1       4.666667  \n",
      "2       6.500000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': ['A', 'B', 'A', 'B', 'A', 'C', 'C', 'B'],\n",
    "    'Value': [10, 20, 30, 40, 50, 60, 70, 80],\n",
    "    'Quantity': [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by Category and compute various statistics\n",
    "grouped = df.groupby('Category').agg({\n",
    "    'Value': ['mean', 'sum', 'min', 'max'],\n",
    "    'Quantity': ['sum', 'mean']\n",
    "})\n",
    "\n",
    "print(\"\\nGrouped and aggregated data:\")\n",
    "print(grouped)\n",
    "\n",
    "# Compute a custom aggregation\n",
    "def range_calc(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "custom_agg = df.groupby('Category').agg({\n",
    "    'Value': range_calc\n",
    "})\n",
    "\n",
    "print(\"\\nCustom aggregation (range of Values for each Category):\")\n",
    "print(custom_agg)\n",
    "\n",
    "# Reset column names for better readability\n",
    "grouped.columns = ['Value_Mean', 'Value_Sum', 'Value_Min', 'Value_Max', 'Quantity_Sum', 'Quantity_Mean']\n",
    "grouped = grouped.reset_index()\n",
    "\n",
    "print(\"\\nGrouped data with reset column names:\")\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Joining DataFrames\n",
    "Merging and joining are essential operations when working with multiple datasets. Pandas provides various methods to combine DataFrames based on common columns or indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1 (Employee Info):\n",
      "   ID     Name Department\n",
      "0   1    Alice         HR\n",
      "1   2      Bob         IT\n",
      "2   3  Charlie    Finance\n",
      "3   4    David  Marketing\n",
      "\n",
      "DataFrame 2 (Salary Info):\n",
      "   ID  Salary  Experience\n",
      "0   2   50000           2\n",
      "1   3   60000           5\n",
      "2   4   55000           3\n",
      "3   5   65000           6\n",
      "\n",
      "Inner Join:\n",
      "   ID     Name Department  Salary  Experience\n",
      "0   2      Bob         IT   50000           2\n",
      "1   3  Charlie    Finance   60000           5\n",
      "2   4    David  Marketing   55000           3\n",
      "\n",
      "Left Join:\n",
      "   ID     Name Department   Salary  Experience\n",
      "0   1    Alice         HR      NaN         NaN\n",
      "1   2      Bob         IT  50000.0         2.0\n",
      "2   3  Charlie    Finance  60000.0         5.0\n",
      "3   4    David  Marketing  55000.0         3.0\n",
      "\n",
      "Right Join:\n",
      "   ID     Name Department  Salary  Experience\n",
      "0   2      Bob         IT   50000           2\n",
      "1   3  Charlie    Finance   60000           5\n",
      "2   4    David  Marketing   55000           3\n",
      "3   5      NaN        NaN   65000           6\n",
      "\n",
      "Full Outer Join:\n",
      "   ID     Name Department   Salary  Experience\n",
      "0   1    Alice         HR      NaN         NaN\n",
      "1   2      Bob         IT  50000.0         2.0\n",
      "2   3  Charlie    Finance  60000.0         5.0\n",
      "3   4    David  Marketing  55000.0         3.0\n",
      "4   5      NaN        NaN  65000.0         6.0\n",
      "\n",
      "Join on Index:\n",
      "       Name Department  Salary  Experience\n",
      "ID                                        \n",
      "2       Bob         IT   50000           2\n",
      "3   Charlie    Finance   60000           5\n",
      "4     David  Marketing   55000           3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Department': ['HR', 'IT', 'Finance', 'Marketing']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [2, 3, 4, 5],\n",
    "    'Salary': [50000, 60000, 55000, 65000],\n",
    "    'Experience': [2, 5, 3, 6]\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1 (Employee Info):\")\n",
    "print(df1)\n",
    "\n",
    "print(\"\\nDataFrame 2 (Salary Info):\")\n",
    "print(df2)\n",
    "\n",
    "# Perform an inner join\n",
    "inner_join = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(\"\\nInner Join:\")\n",
    "print(inner_join)\n",
    "\n",
    "# Perform a left join\n",
    "left_join = pd.merge(df1, df2, on='ID', how='left')\n",
    "print(\"\\nLeft Join:\")\n",
    "print(left_join)\n",
    "\n",
    "# Perform a right join\n",
    "right_join = pd.merge(df1, df2, on='ID', how='right')\n",
    "print(\"\\nRight Join:\")\n",
    "print(right_join)\n",
    "\n",
    "# Perform a full outer join\n",
    "outer_join = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(\"\\nFull Outer Join:\")\n",
    "print(outer_join)\n",
    "\n",
    "# Join on index\n",
    "df1.set_index('ID', inplace=True)\n",
    "df2.set_index('ID', inplace=True)\n",
    "index_join = df1.join(df2, how='inner')\n",
    "print(\"\\nJoin on Index:\")\n",
    "print(index_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series and Date Functionality\n",
    "Pandas has powerful capabilities for working with time series data, including date parsing, resampling, and time-based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame (first 5 rows):\n",
      "               value\n",
      "date                \n",
      "2023-01-01  2.472473\n",
      "2023-01-02  0.226583\n",
      "2023-01-03 -0.109806\n",
      "2023-01-04 -0.581881\n",
      "2023-01-05  0.173813\n",
      "\n",
      "Monthly mean:\n",
      "               value\n",
      "date                \n",
      "2023-01-31 -0.384539\n",
      "2023-02-28  0.091743\n",
      "2023-03-31 -0.092267\n",
      "2023-04-30 -0.262000\n",
      "2023-05-31 -0.276148\n",
      "2023-06-30  0.099764\n",
      "2023-07-31 -0.293593\n",
      "2023-08-31 -0.145879\n",
      "2023-09-30 -0.109738\n",
      "2023-10-31 -0.069448\n",
      "2023-11-30 -0.193152\n",
      "2023-12-31  0.267663\n",
      "\n",
      "DataFrame with 7-day rolling average (last 5 rows):\n",
      "               value  rolling_avg\n",
      "date                             \n",
      "2023-12-27 -0.972355     0.645893\n",
      "2023-12-28 -1.134689     0.255776\n",
      "2023-12-29  0.759711     0.239492\n",
      "2023-12-30 -0.666436     0.302187\n",
      "2023-12-31  0.134798     0.211342\n",
      "\n",
      "Data for June 2023:\n",
      "               value  rolling_avg\n",
      "date                             \n",
      "2023-06-01  1.296393    -0.026037\n",
      "2023-06-02 -0.312324     0.076974\n",
      "2023-06-03 -0.222838    -0.009860\n",
      "2023-06-04  0.080788    -0.007043\n",
      "2023-06-05  1.212477     0.241893\n",
      "2023-06-06  0.582521     0.350037\n",
      "2023-06-07 -2.565849     0.010167\n",
      "2023-06-08  2.436084     0.172980\n",
      "2023-06-09 -0.534884     0.141186\n",
      "2023-06-10 -2.017797    -0.115237\n",
      "2023-06-11  0.904102     0.002379\n",
      "2023-06-12 -1.295982    -0.355972\n",
      "2023-06-13  1.123692    -0.278662\n",
      "2023-06-14  0.833909     0.207018\n",
      "2023-06-15 -1.429986    -0.345278\n",
      "2023-06-16  0.765013    -0.159578\n",
      "2023-06-17  1.868387     0.395591\n",
      "2023-06-18 -0.227511     0.233932\n",
      "2023-06-19  0.424300     0.479686\n",
      "2023-06-20 -0.116956     0.302451\n",
      "2023-06-21 -0.359672     0.131939\n",
      "2023-06-22  0.496905     0.407209\n",
      "2023-06-23 -1.348571     0.105269\n",
      "2023-06-24  0.211146    -0.131480\n",
      "2023-06-25 -0.764424    -0.208182\n",
      "2023-06-26 -0.140389    -0.288852\n",
      "2023-06-27 -0.162464    -0.295353\n",
      "2023-06-28  0.872386    -0.119344\n",
      "2023-06-29 -0.519994    -0.264616\n",
      "2023-06-30  1.904459     0.200103\n",
      "\n",
      "DataFrame with previous day's value (first 5 rows):\n",
      "               value  rolling_avg  previous_day\n",
      "date                                           \n",
      "2023-01-01  2.472473          NaN           NaN\n",
      "2023-01-02  0.226583          NaN      2.472473\n",
      "2023-01-03 -0.109806          NaN      0.226583\n",
      "2023-01-04 -0.581881          NaN     -0.109806\n",
      "2023-01-05  0.173813          NaN     -0.581881\n",
      "\n",
      "DataFrame with year-to-date cumulative sum (last 5 rows):\n",
      "               value  rolling_avg  previous_day  ytd_cumsum\n",
      "date                                                       \n",
      "2023-12-27 -0.972355     0.645893      2.805299  -41.298956\n",
      "2023-12-28 -1.134689     0.255776     -0.972355  -42.433645\n",
      "2023-12-29  0.759711     0.239492     -1.134689  -41.673934\n",
      "2023-12-30 -0.666436     0.302187      0.759711  -42.340369\n",
      "2023-12-31  0.134798     0.211342     -0.666436  -42.205571\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a date range\n",
    "date_rng = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# Create a DataFrame with random data\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['value'] = np.random.randn(len(date_rng))\n",
    "\n",
    "# Set the date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "print(\"Original DataFrame (first 5 rows):\")\n",
    "print(df.head())\n",
    "\n",
    "# Resample to monthly frequency\n",
    "monthly_mean = df.resample('M').mean()\n",
    "print(\"\\nMonthly mean:\")\n",
    "print(monthly_mean)\n",
    "\n",
    "# Calculate rolling average\n",
    "df['rolling_avg'] = df['value'].rolling(window=7).mean()\n",
    "\n",
    "print(\"\\nDataFrame with 7-day rolling average (last 5 rows):\")\n",
    "print(df.tail())\n",
    "\n",
    "# Filter data for a specific date range\n",
    "date_filter = df['2023-06-01':'2023-06-30']\n",
    "print(\"\\nData for June 2023:\")\n",
    "print(date_filter)\n",
    "\n",
    "# Shift data\n",
    "df['previous_day'] = df['value'].shift(1)\n",
    "print(\"\\nDataFrame with previous day's value (first 5 rows):\")\n",
    "print(df.head())\n",
    "\n",
    "# Calculate year-to-date cumulative sum\n",
    "df['ytd_cumsum'] = df.groupby(df.index.year)['value'].cumsum()\n",
    "print(\"\\nDataFrame with year-to-date cumulative sum (last 5 rows):\")\n",
    "print(df.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
